{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# att1: 在retinanet fpn的基础上增加attent，输出还是3变5\n",
    "# att2：在att1基础上，只输出3,4,5；相应的head也要改\n",
    "# att3：在att2基础上，3,4,5输出max-pooling，维度和3一致，之后attn 3个输出；相应的head同2\n",
    "# att4：在att3基础上，maxpooling改avg pooling\n",
    "# att5: att2基础上输出n r loss，新head\n",
    "# att6：att5基础上，不输出多余loss\n",
    "# att7：att6基础上，只迭代一次\n",
    "\n",
    "# att10：att2\n",
    "# att11：att2+weather\n",
    "# att12：att2+weather+wloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import BaseModule, auto_fp16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand(16,256,80,80)\n",
    "b=torch.rand(16,256,40,40)\n",
    "c=torch.rand(16,256,20,20)\n",
    "d=torch.rand(16,256,10,10)\n",
    "e=torch.rand(16,256,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs=[a,b,c,d,e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0_3, p_1_4, p_2_5, p_3_6, p_4_7  = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_cfg=dict(mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "        p_top = ConvModule(\n",
    "                    256,\n",
    "                    256,\n",
    "                    3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "        p_3_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_4_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_5_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_6_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_7_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        level_weight_conv = ConvModule(\n",
    "                    80,\n",
    "                    5,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0_size = p_0_3.shape[2:]\n",
    "p_1_size = p_1_4.shape[2:]\n",
    "p_2_size = p_2_5.shape[2:]\n",
    "p_3_size = p_3_6.shape[2:]\n",
    "p_4_size = p_4_7.shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0_3 = p_0_3\n",
    "p_1_3 = p_top(p_0_3)\n",
    "p_2_3 = p_top(p_1_3)\n",
    "p_3_3 = p_top(p_2_3)\n",
    "p_4_3 = p_top(p_3_3)\n",
    "\n",
    "p_1_4 = p_1_4\n",
    "p_2_4 = p_top(p_1_4)\n",
    "p_3_4 = p_top(p_2_4)\n",
    "p_4_4 = p_top(p_3_4)\n",
    "p_0_4 = F.interpolate(p_1_4, size=p_0_size, **upsample_cfg)\n",
    "\n",
    "p_2_5 = p_2_5\n",
    "p_3_5 = p_top(p_2_5)\n",
    "p_4_5 = p_top(p_3_5)\n",
    "p_1_5 = F.interpolate(p_2_5, size=p_1_size, **upsample_cfg)\n",
    "p_0_5 = F.interpolate(p_1_5, size=p_0_size, **upsample_cfg)\n",
    "\n",
    "p_3_6 = p_3_6\n",
    "p_4_6 = p_top(p_3_6)\n",
    "p_2_6 = F.interpolate(p_3_6, size=p_2_size, **upsample_cfg)\n",
    "p_1_6 = F.interpolate(p_2_6, size=p_1_size, **upsample_cfg)\n",
    "p_0_6 = F.interpolate(p_1_6, size=p_0_size, **upsample_cfg)\n",
    "\n",
    "p_4_7 = p_4_7\n",
    "p_3_7 = F.interpolate(p_4_7, size=p_3_size, **upsample_cfg)\n",
    "p_2_7 = F.interpolate(p_3_7, size=p_2_size, **upsample_cfg)\n",
    "p_1_7 = F.interpolate(p_2_7, size=p_1_size, **upsample_cfg)\n",
    "p_0_7 = F.interpolate(p_1_7, size=p_0_size, **upsample_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "        level_0_weight_3 = p_3_conv(p_0_3)\n",
    "        level_0_weight_4 = p_4_conv(p_0_4)\n",
    "        level_0_weight_5 = p_5_conv(p_0_5)\n",
    "        level_0_weight_6 = p_6_conv(p_0_6)\n",
    "        level_0_weight_7 = p_7_conv(p_0_7)\n",
    "        \n",
    "        level_0_weight_concat = torch.cat((level_0_weight_3, level_0_weight_4, level_0_weight_5, level_0_weight_6, level_0_weight_7),1)\n",
    "        level_0_weight = level_weight_conv(level_0_weight_concat)\n",
    "        level_0_weight = F.softmax(level_0_weight, dim=1)\n",
    "\n",
    "        level_0 = p_0_3 * level_0_weight[:,0:1,:,:]+\\\n",
    "                            p_0_4 * level_0_weight[:,1:2,:,:]+\\\n",
    "                            p_0_5 * level_0_weight[:,2:3,:,:]+\\\n",
    "                            p_0_6 * level_0_weight[:,3:4,:,:]+\\\n",
    "                            p_0_7 * level_0_weight[:,4:,:,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_features=[[p_0_3,p_0_4,p_0_5,p_0_6,p_0_7],\n",
    "[p_1_3,p_1_4,p_1_5,p_1_6,p_1_7],\n",
    "[p_2_3,p_2_4,p_2_5,p_2_6,p_2_7],\n",
    "[p_3_3,p_3_4,p_3_5,p_3_6,p_3_7],\n",
    "[p_4_3,p_4_4,p_4_5,p_4_6,p_4_7],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_feature=[]\n",
    "for i in range(5):\n",
    "        level_weight_3 = p_3_conv(p_features[i][0])\n",
    "        level_weight_4 = p_4_conv(p_features[i][1])\n",
    "        level_weight_5 = p_5_conv(p_features[i][2])\n",
    "        level_weight_6 = p_6_conv(p_features[i][3])\n",
    "        level_weight_7 = p_7_conv(p_features[i][4])\n",
    "        \n",
    "        level_weight_concat = torch.cat((level_weight_3, level_weight_4, level_weight_5, level_weight_6, level_weight_7),1)\n",
    "        level_weight = level_weight_conv(level_weight_concat)\n",
    "        level_weight = F.softmax(level_weight, dim=1)\n",
    "\n",
    "        level = p_features[i][0] * level_weight[:,0:1,:,:]+\\\n",
    "                  p_features[i][1] * level_weight[:,1:2,:,:]+\\\n",
    "                  p_features[i][2] * level_weight[:,2:3,:,:]+\\\n",
    "                  p_features[i][3] * level_weight[:,3:4,:,:]+\\\n",
    "                  p_features[i][4] * level_weight[:,4:,:,:]\n",
    "        out_feature.append(level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        level_0_weight_v = self.weight_level_0(level_0_resized)\n",
    "        level_1_weight_v = self.weight_level_1(level_1_resized)\n",
    "        level_2_weight_v = self.weight_level_2(level_2_resized)\n",
    "        levels_weight_v = torch.cat((level_0_weight_v, level_1_weight_v, level_2_weight_v),1)\n",
    "        levels_weight = self.weight_levels(levels_weight_v)\n",
    "        levels_weight = F.softmax(levels_weight, dim=1)\n",
    "\n",
    "        fused_out_reduced = level_0_resized * levels_weight[:,0:1,:,:]+\\\n",
    "                            level_1_resized * levels_weight[:,1:2,:,:]+\\\n",
    "                            level_2_resized * levels_weight[:,2:,:,:]\n",
    "\n",
    "        out = self.expand(fused_out_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "        p_top = ConvModule(\n",
    "                    256,\n",
    "                    256,\n",
    "                    3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_3_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_4_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        p_5_conv = ConvModule(\n",
    "                    256,\n",
    "                    16,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        # self.p_6_conv = ConvModule(\n",
    "        #             256,\n",
    "        #             16,\n",
    "        #             1,\n",
    "        #             stride=1,\n",
    "        #             padding=0,\n",
    "        #             conv_cfg=None,\n",
    "        #             norm_cfg=None,\n",
    "        #             act_cfg=None,\n",
    "        #             inplace=False)\n",
    "        # self.p_7_conv = ConvModule(\n",
    "        #             256,\n",
    "        #             16,\n",
    "        #             1,\n",
    "        #             stride=1,\n",
    "        #             padding=0,\n",
    "        #             conv_cfg=None,\n",
    "        #             norm_cfg=None,\n",
    "        #             act_cfg=None,\n",
    "        #             inplace=False)\n",
    "        level_weight_conv = ConvModule(\n",
    "                    48,\n",
    "                    3,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    padding=0,\n",
    "                    conv_cfg=None,\n",
    "                    norm_cfg=None,\n",
    "                    act_cfg=None,\n",
    "                    inplace=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # outs=[p_0_3,          p_1_4,      p_2_5,      p_3_6,      p_4_7]\n",
    "        #       60*60*256(8)    40*40*256   20*20*256   10*10*256   5*5*256\n",
    "        p_0_3, p_1_4, p_2_5, p_3_6, p_4_7  = outs\n",
    "        p_0_size = p_0_3.shape[2:]\n",
    "        p_1_size = p_1_4.shape[2:]\n",
    "        p_2_size = p_2_5.shape[2:]\n",
    "        # p_3_size = p_3_6.shape[2:]\n",
    "        # p_4_size = p_4_7.shape[2:]\n",
    "\n",
    "        p_0_3 = p_0_3\n",
    "        p_1_3 = p_top(p_0_3)\n",
    "        p_2_3 = p_top(p_1_3)\n",
    "        # p_3_3 = self.p_top(p_2_3)\n",
    "        # p_4_3 = self.p_top(p_3_3)\n",
    "\n",
    "        p_1_4 = p_1_4\n",
    "        p_2_4 = p_top(p_1_4)\n",
    "        # p_3_4 = self.p_top(p_2_4)\n",
    "        # p_4_4 = self.p_top(p_3_4)\n",
    "        p_0_4 = F.interpolate(p_1_4, size=p_0_size, **upsample_cfg)\n",
    "\n",
    "        p_2_5 = p_2_5\n",
    "        # p_3_5 = self.p_top(p_2_5)\n",
    "        # p_4_5 = self.p_top(p_3_5)\n",
    "        p_1_5 = F.interpolate(p_2_5, size=p_1_size, **upsample_cfg)\n",
    "        p_0_5 = F.interpolate(p_1_5, size=p_0_size, **upsample_cfg)\n",
    "\n",
    "        # p_3_6 = p_3_6\n",
    "        # p_4_6 = self.p_top(p_3_6)\n",
    "        # p_2_6 = F.interpolate(p_3_6, size=p_2_size, **self.upsample_cfg)\n",
    "        # p_1_6 = F.interpolate(p_2_6, size=p_1_size, **self.upsample_cfg)\n",
    "        # p_0_6 = F.interpolate(p_1_6, size=p_0_size, **self.upsample_cfg)\n",
    "\n",
    "        # p_4_7 = p_4_7\n",
    "        # p_3_7 = F.interpolate(p_4_7, size=p_3_size, **self.upsample_cfg)\n",
    "        # p_2_7 = F.interpolate(p_3_7, size=p_2_size, **self.upsample_cfg)\n",
    "        # p_1_7 = F.interpolate(p_2_7, size=p_1_size, **self.upsample_cfg)\n",
    "        # p_0_7 = F.interpolate(p_1_7, size=p_0_size, **self.upsample_cfg)\n",
    "\n",
    "        # p_features=[[p_0_3,p_0_4,p_0_5,p_0_6,p_0_7],\n",
    "        #             [p_1_3,p_1_4,p_1_5,p_1_6,p_1_7],\n",
    "        #             [p_2_3,p_2_4,p_2_5,p_2_6,p_2_7],\n",
    "        #             [p_3_3,p_3_4,p_3_5,p_3_6,p_3_7],\n",
    "        #             [p_4_3,p_4_4,p_4_5,p_4_6,p_4_7],]\n",
    "        p_features=[[p_0_3,p_0_4,p_0_5],\n",
    "            [p_1_3,p_1_4,p_1_5],\n",
    "            [p_2_3,p_2_4,p_2_5]]\n",
    "\n",
    "        out_feature=[]\n",
    "        for i in range(3):\n",
    "                level_weight_3 = p_3_conv(p_features[i][0])\n",
    "                level_weight_4 = p_4_conv(p_features[i][1])\n",
    "                level_weight_5 = p_5_conv(p_features[i][2])\n",
    "\n",
    "                \n",
    "                level_weight_concat = torch.cat((level_weight_3, level_weight_4, level_weight_5),1)\n",
    "                level_weight = level_weight_conv(level_weight_concat)\n",
    "                level_weight = F.softmax(level_weight, dim=1)\n",
    "\n",
    "                level = p_features[i][0] * level_weight[:,0:1,:,:]+\\\n",
    "                        p_features[i][1] * level_weight[:,1:2,:,:]+\\\n",
    "                        p_features[i][2] * level_weight[:,2:,:,:]\n",
    "                out_feature.append(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 80, 80])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_feature[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 256, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv2 = nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding =1)\n",
    "deconv4 = nn.ConvTranspose2d(256, 256, 3, stride=4, padding=0, output_padding =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_0_3 p_1_4 p_2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pool_3 = p_0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pool_4 = deconv2(p_1_4)\n",
    "p_pool_5 = deconv4(p_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = (p_pool_3+p_pool_4+p_pool_5)/3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 80, 80])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0, p_1, p_2, p_3, p_4  = outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\trelu = nn.ReLU(inplace=True) \n",
    "\n",
    "\t\tnumber_f = 32\n",
    "\t\te_conv1 = nn.Conv2d(256,number_f,3,1,1,bias=True)\n",
    "\t\te_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
    "\t\te_conv3 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
    "\t\te_conv4 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
    "\t\te_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
    "\t\te_conv7 = nn.Conv2d(number_f*2,8,3,1,1,bias=True) \n",
    "\t\te_conv8 = nn.Conv2d(number_f*2,8,3,1,1,bias=True) \n",
    "\t\tmaxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
    "\t\tupsample = nn.UpsamplingBilinear2d(scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\tx=p_0\n",
    "\t\tx1 = relu(e_conv1(x))\n",
    "\t\tx2 = relu(e_conv2(x1))\n",
    "\t\tx3 = relu(e_conv3(torch.cat([x1,x2],1)))\n",
    "\t\tx4 = relu(e_conv4(torch.cat([x2,x3],1)))\n",
    "\t\tx5 = relu(e_conv5(torch.cat([x3,x4],1)))\n",
    "\t\tx_r = torch.tanh(e_conv7(torch.cat([x4,x5],1)))\n",
    "\t\tx_n = torch.tanh(e_conv8(torch.cat([x4,x5],1)))\n",
    "\t\tr1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 1, dim=1)\n",
    "\t\tn1,n2,n3,n4,n5,n6,n7,n8 = torch.split(x_n, 1, dim=1)\n",
    "\n",
    "\t\tx = (x-n1) * (r1+1)\n",
    "\t\tx = (x-n2) * (r2+1)\n",
    "\t\tx = (x-n3) * (r3+1)\n",
    "\t\tenhance_image_1 = (x-n4) * (r4+1)\n",
    "\t\tx = (enhance_image_1-n5) * (r5+1)\n",
    "\t\tx = (x-n6) * (r6+1)\n",
    "\t\tx = (x-n7) * (r7+1)\n",
    "\t\tenhance_image = (x-n8) * (r8+1)\n",
    "\t\t\n",
    "\t\tr = torch.cat([(r1+1),(r2+1),(r3+1),(r4+1),(r5+1),(r6+1),(r7+1),(r8+1)],1)\n",
    "\t\tn = torch.cat([n1,n2,n3,n4,n5,n6,n7,n8],1)\n",
    "\t\t# return enhance_image,r, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 80, 80])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance_image2= torch.cat([enhance_image,r,n],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 272, 80, 80])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "        feat = enhance_image2[:,0:256,:,:]\n",
    "        r = enhance_image2[:,256:264,:,:]\n",
    "        n = enhance_image2[:,264:272,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 272, 80, 80])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 80, 80])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_image2[:,-8:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 80, 80])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_image2[:,-16:-8,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 80, 80])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhance_image2[:,:-16,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torchvision.models.vgg import vgg16\n",
    "#import pytorch_colors as colors\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "class L_color(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(L_color, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #bias = 0.00001\n",
    "        #x = torch.div(x_o,x_i+bias)\n",
    "        #x = x_o\n",
    "        b,c,h,w = x.shape\n",
    "        '''\n",
    "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
    "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
    "        Drg = torch.pow(mr-mg,2)\n",
    "        Drb = torch.pow(mr-mb,2)\n",
    "        Dgb = torch.pow(mb-mg,2)\n",
    "        k = torch.pow(torch.pow(Drg,2) + torch.pow(Drb,2) + torch.pow(Dgb,2),0.5)\n",
    "        '''\n",
    "        r, g, b = torch.split(x, 1, dim=1)\n",
    "        pow_r = torch.norm(r, dim=(2,3))\n",
    "        pow_g = torch.norm(g, dim=(2,3))\n",
    "        pow_b = torch.norm(b, dim=(2,3))\n",
    "\n",
    "        return (torch.pow(pow_r - pow_g, 2) + torch.pow(pow_r - pow_b, 2) + torch.pow(pow_b - pow_g, 2)) / (h*w)\n",
    "\n",
    "\n",
    "def weights_map(Size):\n",
    "    V=np.zeros(Size)\n",
    "    x = np.append(np.matrix(np.arange(0,8)).getA(),np.matrix(np.arange(7,-1,-1)).getA())\n",
    "    for i in range(0,Size[0]):\n",
    "        for j in range(0,Size[1]):\n",
    "            V[i][j] = math.log(math.e + math.sqrt(x[i]**2+x[j]**2))\n",
    "    return torch.from_numpy(V).cuda()\n",
    "class L_cen(nn.Module):\n",
    "\n",
    "    def __init__(self,patch_size,mean_val):\n",
    "        super(L_cen, self).__init__()\n",
    "        # print(1)\n",
    "        self.pool = nn.AvgPool2d(patch_size)\n",
    "        self.mean_val = mean_val\n",
    "\n",
    "    def forward(self, x ):\n",
    "\n",
    "        b,c,h,w = x.shape\n",
    "        x = torch.mean(x,1,keepdim=True)\n",
    "        mean = self.pool(x)\n",
    "\n",
    "        d = torch.mean(torch.pow((mean- torch.FloatTensor([self.mean_val] ).cuda())* weights_map((16,16)).squeeze(0).squeeze(0) ,2))\n",
    "        return d\n",
    "\n",
    "\n",
    "\n",
    "class L_ill(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L_ill,self).__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
    "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return (h_tv/count_h+w_tv/count_w)/batch_size\n",
    "\n",
    "\n",
    "class perception_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(perception_loss, self).__init__()\n",
    "        features = vgg16(pretrained=True).features.cuda()\n",
    "        self.to_relu_1_2 = nn.Sequential() \n",
    "        self.to_relu_2_2 = nn.Sequential() \n",
    "        self.to_relu_3_3 = nn.Sequential()\n",
    "        self.to_relu_4_3 = nn.Sequential()\n",
    "\n",
    "        for x in range(4):\n",
    "            self.to_relu_1_2.add_module(str(x), features[x])\n",
    "        for x in range(4, 9):\n",
    "            self.to_relu_2_2.add_module(str(x), features[x])\n",
    "        for x in range(9, 16):\n",
    "            self.to_relu_3_3.add_module(str(x), features[x])\n",
    "        for x in range(16, 23):\n",
    "            self.to_relu_4_3.add_module(str(x), features[x])\n",
    "        \n",
    "        # don't need the gradients, just want the features\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.cpu()\n",
    "        h = self.to_relu_1_2(x)\n",
    "        h_relu_1_2 = h\n",
    "        h = self.to_relu_2_2(h)\n",
    "        h_relu_2_2 = h\n",
    "        h = self.to_relu_3_3(h)\n",
    "        h_relu_3_3 = h\n",
    "        h = self.to_relu_4_3(h)\n",
    "        h_relu_4_3 = h\n",
    "        # out = (h_relu_1_2, h_relu_2_2, h_relu_3_3, h_relu_4_3)\n",
    "        return h_relu_4_3\n",
    "\n",
    "\n",
    "class noise_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(noise_loss, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        loss = torch.pow(torch.norm(x, dim=(2,3)), 2)\n",
    "        return torch.mean(loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # L_ill(r)\n",
    "        x=r\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
    "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        # return (h_tv/count_h+w_tv/count_w)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h_tv/count_h+w_tv/count_w)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(L_noi(n))\n",
    "x=n\n",
    "batch_size = x.size()[0]\n",
    "loss = torch.pow(torch.norm(x, dim=(2,3)), 2)\n",
    "# return torch.mean(loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4550, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.mean(loss,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\tenhanced_image,A,N  = DarkLighter(img_lowlight)\n",
    "\n",
    "\t\t\tLoss_ill = 1600*L_ill(A)\n",
    "\t\t\t\n",
    "\t\t\tloss_col = 50*torch.mean(L_color(enhanced_image))\n",
    "\n",
    "\t\t\tloss_cen = 10*torch.mean(L_cen(enhanced_image))\n",
    "\t\t\t\n",
    "\t\t\tloss_perc = 0.001*torch.norm(L_perc(enhanced_image) - L_perc(img_lowlight))\n",
    "\n",
    "\t\t\tloss_noise = 50*torch.mean(L_noi(N))\n",
    "\n",
    "\t\t\tloss =    Loss_ill   +loss_cen +  loss_col + loss_perc+ loss_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand(2, 8, 68, 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "        x=a\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
    "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6559)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h_tv/count_h+w_tv/count_w)/batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('openmmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "311e10a10a76ebc960efc0ae7ebe279857be68a266d15bd01057fc01c6af86ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
